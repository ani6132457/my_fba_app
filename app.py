import streamlit as st
import pandas as pd
from io import BytesIO
import uuid
from datetime import datetime, timedelta, timezone
import numpy as np

st.set_page_config(layout="wide")
st.title("FBAæ¥­å‹™æ”¯æ´ã‚¢ãƒ—ãƒªï¼ˆCSVå‡ºåŠ›ï¼‹å°åˆ·è¡¨ç¤ºï¼‰")

# CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type="csv")

# SKUå¯¾å¿œè¡¨ã®èª­ã¿è¾¼ã¿ï¼ˆå›ºå®šãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
sku_master_path = "data/sku_master.xlsx"
df_master = pd.read_excel(sku_master_path)

# å°åˆ·ç”¨HTMLï¼ˆè‡ªå‹•ã§å°åˆ·ãƒ€ã‚¤ã‚¢ãƒ­ã‚°ãŒé–‹ãï¼‰
def generate_auto_print_html(df):
    df = df[df['SKU'].notna() & df['å•†å“å_x'].notna()]
    df = df.sort_values("SKU")
    html = """
    <html><head><meta charset='utf-8'>
    <script>window.onload = function() { window.print(); }</script>
    <style>
    body { font-family: 'Yu Gothic', sans-serif; font-size: 10pt; }
    table { width: 100%; border-collapse: collapse; page-break-after: always; }
    th, td { border: 1px solid #333; padding: 4px; }
    th { background-color: #f0f0f0; }
    td.wrap { word-wrap: break-word; white-space: normal; }
    td.nowrap { white-space: nowrap; }
    </style></head><body>
    <h3>ãƒ”ãƒƒã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆ</h3>
    <table>
    <tr><th style='width:15%'>SKU</th><th style='width:45%'>å•†å“å</th><th style='width:10%'>æ•°é‡</th><th style='width:15%'>ã‚¿ã‚¤ãƒ—1</th><th style='width:15%'>ã‚¿ã‚¤ãƒ—2</th></tr>
    """
    for _, row in df.iterrows():
        t1 = row['ã‚¿ã‚¤ãƒ—1'] if pd.notna(row['ã‚¿ã‚¤ãƒ—1']) else ''
        t2 = row['ã‚¿ã‚¤ãƒ—2'] if pd.notna(row['ã‚¿ã‚¤ãƒ—2']) else ''
        html += f"<tr><td>{row['SKU']}</td><td class='wrap'>{row['å•†å“å_x']}</td><td>{row['æ•°é‡']}</td><td class='nowrap'>{t1}</td><td class='nowrap'>{t2}</td></tr>"
    html += f"</table><!-- {uuid.uuid4()} --></body></html>"
    return html

# æ•°é‡ã®ãƒã‚¤ãƒŠã‚¹å¤‰æ›ï¼ˆå®‰å…¨å‡¦ç†ï¼‰
def safe_negate(value):
    try:
        return -int(value)
    except:
        return ""

if uploaded_file:
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰CSVèª­ã¿è¾¼ã¿ï¼ˆ6è¡Œç›®ãŒãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰
    df_csv = pd.read_csv(uploaded_file, skiprows=5)

    # SKUå‰å‡¦ç†ï¼ˆç©ºç™½ãªã©é™¤å»ï¼‰
    df_csv['SKU'] = df_csv['SKU'].astype(str).str.strip()

    # SKUãƒã‚¹ã‚¿ã¨ãƒãƒ¼ã‚¸
    merged_df = df_csv.merge(df_master, left_on="SKU", right_on="AmazonSKU", how="left")

    # Excelã¨åŒæ§˜ã®IFï¼‹XLOOKUPãƒ­ã‚¸ãƒƒã‚¯ã®å†ç¾
    merged_df["å•†å“ã‚³ãƒ¼ãƒ‰"] = merged_df.apply(
        lambda row: "" if row["SKU"] == "" else (row["ãƒ†ãƒ³ãƒã‚¹ã‚¿ãƒ¼SKU"] if pd.notna(row["ãƒ†ãƒ³ãƒã‚¹ã‚¿ãƒ¼SKU"]) else row["SKU"]),
        axis=1
    )

    stock_df = merged_df[["å•†å“ã‚³ãƒ¼ãƒ‰", "æ•°é‡"]].copy()
    stock_df["æ•°é‡"] = stock_df["æ•°é‡"].apply(safe_negate)

    # æ–‡å­—åˆ—"nan"ã€np.nanã€NaNã‚’å®Œå…¨ã«ç©ºæ–‡å­—ã«ç½®æ›
    stock_df = stock_df.replace(["nan", "NaN", np.nan], "").astype(str)

    # ç©ºç™½ã®è¡Œï¼ˆå•†å“ã‚³ãƒ¼ãƒ‰ãƒ»æ•°é‡ãŒä¸¡æ–¹ç©ºï¼‰ã‚’å‰Šé™¤
    stock_df = stock_df[~((stock_df["å•†å“ã‚³ãƒ¼ãƒ‰"] == "") & (stock_df["æ•°é‡"] == ""))]

    csv_buffer = BytesIO()
    stock_df.to_csv(csv_buffer, index=False, encoding="utf-8-sig")

    # JSTï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰ã§ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ç”¨
    JST = timezone(timedelta(hours=9))
    now = datetime.now(JST).strftime('%Y-%m-%d_%H-%M')
    file_name = f"åœ¨åº«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿_{now}.csv"

    st.download_button("ğŸ“¥ åœ¨åº«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv_buffer.getvalue(), file_name=file_name, mime="text/csv")

    # å°åˆ·ç”¨ãƒ”ãƒƒã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆã‚’è¡¨ç¤ºï¼ˆå°åˆ·ãƒ€ã‚¤ã‚¢ãƒ­ã‚°è‡ªå‹•èµ·å‹•ï¼‰
    st.subheader("ğŸ–¨ ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯å°åˆ·ï¼šãƒ”ãƒƒã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆ")
    if st.button("ğŸ“„ ãƒ”ãƒƒã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆã‚’å°åˆ·"):
        html_content = generate_auto_print_html(merged_df)
        st.components.v1.html(html_content, height=1500, scrolling=True)
