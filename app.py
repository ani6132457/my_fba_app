import streamlit as st
import pandas as pd
from io import BytesIO

st.set_page_config(layout="wide")
st.title("FBAæ¥­å‹™æ”¯æ´ã‚¢ãƒ—ãƒªï¼ˆCSVå‡ºåŠ›ï¼‹å°åˆ·è¡¨ç¤ºï¼‰")

# CSVã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type="csv")

# SKUå¯¾å¿œè¡¨ã®èª­ã¿è¾¼ã¿ï¼ˆå›ºå®šãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
sku_master_path = "data/sku_master.xlsx"
df_master = pd.read_excel(sku_master_path)

# HTMLä¿å­˜ã¨è¡¨ç¤ºãƒªãƒ³ã‚¯ä½œæˆ
def save_html_and_get_url(html):
    html_path = "/tmp/picking_list.html"
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(html)
    return f"<a href='picking_list.html' target='_blank'>ğŸ–¨ ãƒ”ãƒƒã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆã‚’åˆ¥ã‚¿ãƒ–ã§é–‹ã</a>"

# å°åˆ·ç”¨HTMLã‚’ç”Ÿæˆ
def generate_html_table(df):
    df = df[df['SKU'].notna() & df['å•†å“å_x'].notna()]
    html = """
    <html><head><meta charset='utf-8'>
    <style>
    @media print {
        body { font-family: 'Yu Gothic', sans-serif; font-size: 10pt; }
        table { width: 100%; border-collapse: collapse; page-break-after: always; }
        th, td { border: 1px solid #333; padding: 4px; }
        th { background-color: #f0f0f0; }
        td.wrap { word-wrap: break-word; white-space: normal; }
        td.nowrap { white-space: nowrap; }
    }
    </style></head><body>
    <h3>ãƒ”ãƒƒã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆ</h3>
    <table>
    <tr><th style='width:15%'>SKU</th><th style='width:45%'>å•†å“å</th><th style='width:10%'>æ•°é‡</th><th style='width:15%'>ã‚¿ã‚¤ãƒ—1</th><th style='width:15%'>ã‚¿ã‚¤ãƒ—2</th></tr>
    """
    for _, row in df.iterrows():
        t1 = row['ã‚¿ã‚¤ãƒ—1'] if pd.notna(row['ã‚¿ã‚¤ãƒ—1']) else ''
        t2 = row['ã‚¿ã‚¤ãƒ—2'] if pd.notna(row['ã‚¿ã‚¤ãƒ—2']) else ''
        html += f"<tr><td>{row['SKU']}</td><td class='wrap'>{row['å•†å“å_x']}</td><td>{row['æ•°é‡']}</td><td class='nowrap'>{t1}</td><td class='nowrap'>{t2}</td></tr>"
    html += "</table></body></html>"
    return html

if uploaded_file:
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰CSVèª­ã¿è¾¼ã¿ï¼ˆ6è¡Œç›®ãŒãƒ˜ãƒƒãƒ€ãƒ¼ï¼‰
    df_csv = pd.read_csv(uploaded_file, skiprows=5)

    # SKUãƒã‚¹ã‚¿ã¨ãƒãƒ¼ã‚¸
    merged_df = df_csv.merge(df_master, left_on="SKU", right_on="AmazonSKU", how="left")

    # åœ¨åº«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨CSVå‡ºåŠ›
    stock_df = merged_df[merged_df['SKU'].notna()][["ãƒ†ãƒ³ãƒã‚¹ã‚¿ãƒ¼SKU", "æ•°é‡"]].copy()
    stock_df["æ•°é‡"] = stock_df["æ•°é‡"].apply(lambda x: -int(x) if pd.notna(x) else "")
    stock_df.columns = ["å•†å“ã‚³ãƒ¼ãƒ‰", "æƒ³å®šåœ¨åº«æ•°"]

    csv_buffer = BytesIO()
    stock_df.to_csv(csv_buffer, index=False, encoding="utf-8-sig")
    st.download_button("ğŸ“¥ åœ¨åº«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv_buffer.getvalue(), file_name="åœ¨åº«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿.csv", mime="text/csv")

    # å°åˆ·è¡¨ç¤ºãƒªãƒ³ã‚¯ï¼ˆåˆ¥ã‚¿ãƒ–ï¼‰
    st.subheader("ğŸ–¨ ãƒ”ãƒƒã‚­ãƒ³ã‚°ãƒªã‚¹ãƒˆï¼ˆåˆ¥ã‚¿ãƒ–ã§é–‹ãï¼‰")
    html_content = generate_html_table(merged_df)
    st.components.v1.html(save_html_and_get_url(html_content), height=50, scrolling=False)
